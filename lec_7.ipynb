{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBZKMK0K69HDuWl2otnTFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangyups/PyTorchZeroToAll/blob/main/lec_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw3mvvRrXqo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5cc414-f81d-4b4b-9b36-50375a5c75c2"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "xy = np.loadtxt('/content/gdrive/My Drive/Colab Notebooks/diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        out1 = self.sigmoid(self.l1(x))\n",
        "        out2 = self.sigmoid(self.l2(out1))\n",
        "        y_pred = self.sigmoid(self.l3(out2))\n",
        "        return y_pred\n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n",
            "0 0.6537075042724609\n",
            "1 0.6527606844902039\n",
            "2 0.6519213318824768\n",
            "3 0.6511769890785217\n",
            "4 0.6505165696144104\n",
            "5 0.6499305963516235\n",
            "6 0.6494103670120239\n",
            "7 0.6489484310150146\n",
            "8 0.6485381126403809\n",
            "9 0.6481735110282898\n",
            "10 0.6478495597839355\n",
            "11 0.6475615501403809\n",
            "12 0.6473054885864258\n",
            "13 0.6470776796340942\n",
            "14 0.6468750238418579\n",
            "15 0.6466947197914124\n",
            "16 0.6465343236923218\n",
            "17 0.6463913917541504\n",
            "18 0.6462642550468445\n",
            "19 0.6461510062217712\n",
            "20 0.6460501551628113\n",
            "21 0.6459602117538452\n",
            "22 0.6458801627159119\n",
            "23 0.6458088159561157\n",
            "24 0.6457450985908508\n",
            "25 0.6456884145736694\n",
            "26 0.6456378698348999\n",
            "27 0.6455927491188049\n",
            "28 0.6455525159835815\n",
            "29 0.645516574382782\n",
            "30 0.6454845070838928\n",
            "31 0.6454558372497559\n",
            "32 0.6454303860664368\n",
            "33 0.6454075574874878\n",
            "34 0.6453871726989746\n",
            "35 0.6453689336776733\n",
            "36 0.6453526616096497\n",
            "37 0.6453381180763245\n",
            "38 0.6453251242637634\n",
            "39 0.6453134417533875\n",
            "40 0.6453030109405518\n",
            "41 0.6452937126159668\n",
            "42 0.6452853083610535\n",
            "43 0.6452777981758118\n",
            "44 0.6452710628509521\n",
            "45 0.6452651023864746\n",
            "46 0.6452596187591553\n",
            "47 0.6452547311782837\n",
            "48 0.6452503800392151\n",
            "49 0.6452464461326599\n",
            "50 0.6452428698539734\n",
            "51 0.6452396512031555\n",
            "52 0.6452367901802063\n",
            "53 0.6452341675758362\n",
            "54 0.6452318429946899\n",
            "55 0.6452296376228333\n",
            "56 0.6452276706695557\n",
            "57 0.6452258825302124\n",
            "58 0.6452242732048035\n",
            "59 0.6452227234840393\n",
            "60 0.6452213525772095\n",
            "61 0.645220160484314\n",
            "62 0.6452189683914185\n",
            "63 0.6452178955078125\n",
            "64 0.6452170014381409\n",
            "65 0.6452160477638245\n",
            "66 0.6452151536941528\n",
            "67 0.6452143788337708\n",
            "68 0.6452136635780334\n",
            "69 0.6452128887176514\n",
            "70 0.6452122926712036\n",
            "71 0.6452116966247559\n",
            "72 0.6452111005783081\n",
            "73 0.6452105045318604\n",
            "74 0.6452099680900574\n",
            "75 0.6452094912528992\n",
            "76 0.6452089548110962\n",
            "77 0.645208477973938\n",
            "78 0.6452080011367798\n",
            "79 0.6452075839042664\n",
            "80 0.6452071666717529\n",
            "81 0.6452067494392395\n",
            "82 0.6452063322067261\n",
            "83 0.6452059149742126\n",
            "84 0.645205557346344\n",
            "85 0.6452051401138306\n",
            "86 0.6452047824859619\n",
            "87 0.6452044248580933\n",
            "88 0.6452040672302246\n",
            "89 0.6452036499977112\n",
            "90 0.6452032923698425\n",
            "91 0.6452029347419739\n",
            "92 0.6452025771141052\n",
            "93 0.6452022790908813\n",
            "94 0.6452018618583679\n",
            "95 0.645201563835144\n",
            "96 0.6452012062072754\n",
            "97 0.6452008485794067\n",
            "98 0.6452005505561829\n",
            "99 0.645200252532959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-SbcNa7wUs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eab58cb-1acd-432d-ea3c-09fff8aa7bfc"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "xy = np.loadtxt('/content/gdrive/My Drive/Colab Notebooks/diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))\n",
        "print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.l1 = torch.nn.Linear(8, 6)\n",
        "        self.l2 = torch.nn.Linear(6, 4)\n",
        "        self.l3 = torch.nn.Linear(4, 1)\n",
        "        self.relu = F.relu\n",
        "    def forward(self, x):\n",
        "        out1 = self.relu(self.l1(x))\n",
        "        out2 = self.relu(self.l2(out1))\n",
        "        y_pred = self.relu(self.l3(out2))\n",
        "        return y_pred\n",
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "    y_pred = model(x_data)\n",
        "\n",
        "    loss = criterion(y_pred, y_data)\n",
        "    print(epoch, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n",
            "0 0.3773941695690155\n",
            "1 0.32296016812324524\n",
            "2 0.2881730794906616\n",
            "3 0.2659471929073334\n",
            "4 0.25174659490585327\n",
            "5 0.24266955256462097\n",
            "6 0.2368709295988083\n",
            "7 0.2331697791814804\n",
            "8 0.23080497980117798\n",
            "9 0.2292918562889099\n",
            "10 0.22832351922988892\n",
            "11 0.22770217061042786\n",
            "12 0.22730188071727753\n",
            "13 0.22704213857650757\n",
            "14 0.2268725037574768\n",
            "15 0.22676067054271698\n",
            "16 0.22668570280075073\n",
            "17 0.22663454711437225\n",
            "18 0.2265983521938324\n",
            "19 0.22657175362110138\n",
            "20 0.22655171155929565\n",
            "21 0.2265360802412033\n",
            "22 0.2265234738588333\n",
            "23 0.22651240229606628\n",
            "24 0.22650250792503357\n",
            "25 0.22649402916431427\n",
            "26 0.22648607194423676\n",
            "27 0.22647836804389954\n",
            "28 0.22647078335285187\n",
            "29 0.22646339237689972\n",
            "30 0.22645632922649384\n",
            "31 0.2264496237039566\n",
            "32 0.22644276916980743\n",
            "33 0.22643612325191498\n",
            "34 0.22642916440963745\n",
            "35 0.22642169892787933\n",
            "36 0.22641398012638092\n",
            "37 0.2264058142900467\n",
            "38 0.22639751434326172\n",
            "39 0.22638916969299316\n",
            "40 0.22638079524040222\n",
            "41 0.22637224197387695\n",
            "42 0.2263636291027069\n",
            "43 0.22635479271411896\n",
            "44 0.22634553909301758\n",
            "45 0.22633643448352814\n",
            "46 0.22632695734500885\n",
            "47 0.2263171523809433\n",
            "48 0.22630633413791656\n",
            "49 0.2262955605983734\n",
            "50 0.22628411650657654\n",
            "51 0.22627268731594086\n",
            "52 0.22626037895679474\n",
            "53 0.22624742984771729\n",
            "54 0.22623278200626373\n",
            "55 0.2262178361415863\n",
            "56 0.2262020856142044\n",
            "57 0.22618511319160461\n",
            "58 0.22616754472255707\n",
            "59 0.22614946961402893\n",
            "60 0.2261323183774948\n",
            "61 0.22611606121063232\n",
            "62 0.2260996252298355\n",
            "63 0.22608211636543274\n",
            "64 0.22606521844863892\n",
            "65 0.22604817152023315\n",
            "66 0.22603145241737366\n",
            "67 0.22601282596588135\n",
            "68 0.2259947657585144\n",
            "69 0.22597703337669373\n",
            "70 0.2259598672389984\n",
            "71 0.22594305872917175\n",
            "72 0.22592619061470032\n",
            "73 0.22590947151184082\n",
            "74 0.22589251399040222\n",
            "75 0.22587454319000244\n",
            "76 0.22585660219192505\n",
            "77 0.22583743929862976\n",
            "78 0.22581802308559418\n",
            "79 0.22579926252365112\n",
            "80 0.2257804274559021\n",
            "81 0.22576263546943665\n",
            "82 0.22574399411678314\n",
            "83 0.2257261574268341\n",
            "84 0.2257089763879776\n",
            "85 0.225691020488739\n",
            "86 0.22567212581634521\n",
            "87 0.2256532609462738\n",
            "88 0.2256341427564621\n",
            "89 0.2256157249212265\n",
            "90 0.22559654712677002\n",
            "91 0.22557634115219116\n",
            "92 0.22555474936962128\n",
            "93 0.22553318738937378\n",
            "94 0.22551175951957703\n",
            "95 0.2254890352487564\n",
            "96 0.22546616196632385\n",
            "97 0.2254422903060913\n",
            "98 0.22541841864585876\n",
            "99 0.22539493441581726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_M6iKCi0e0B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}